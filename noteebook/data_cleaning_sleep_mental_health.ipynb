{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Limpieza de datos: Sueño ↔ Mala Salud Mental (NHANES 2009–2012)\n",
        "\n",
        "Este cuaderno replica el enfoque de `noteebook/data_cleaning_sexual_behavior.ipynb` pero enfocado en la relación sueño ↔ mala salud mental.\n",
        "\n",
        "Objetivos:\n",
        "- Cargar datos crudos (`NHANES2009-2012.csv`).\n",
        "- Limpiar y documentar: valores únicos, faltantes, rangos plausibles, outliers, duplicados y atributos redundantes.\n",
        "- Generar variables normalizadas (z-score y min-max) para comparaciones.\n",
        "- Calcular correlaciones Pearson y Spearman entre `SleepHrsNight` y `DaysMentHlthBad`.\n",
        "- Exportar un CSV limpio y un informe `.md` con decisiones y resultados.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "PermissionError",
          "evalue": "[Errno 13] Permission denied: '/home/camilo-pc'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/pathlib.py:1116\u001b[39m, in \u001b[36mPath.mkdir\u001b[39m\u001b[34m(self, mode, parents, exist_ok)\u001b[39m\n\u001b[32m   1115\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1116\u001b[39m     \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1117\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n",
            "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/home/camilo-pc/gestion-datos/sleep_mental_health'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/pathlib.py:1116\u001b[39m, in \u001b[36mPath.mkdir\u001b[39m\u001b[34m(self, mode, parents, exist_ok)\u001b[39m\n\u001b[32m   1115\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1116\u001b[39m     \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1117\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n",
            "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/home/camilo-pc/gestion-datos'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[31mPermissionError\u001b[39m                           Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m DATA_RAW = Path(\u001b[33m'\u001b[39m\u001b[33m/home/camilo-pc/gestion-datos/NHANES2009-2012.csv\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      7\u001b[39m OUT_DIR = Path(\u001b[33m'\u001b[39m\u001b[33m/home/camilo-pc/gestion-datos/sleep_mental_health\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[43mOUT_DIR\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparents\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m CSV_OUT = OUT_DIR / \u001b[33m'\u001b[39m\u001b[33mNHANES2009-2012_sleep_mental_clean.csv\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     10\u001b[39m REPORT_MD = OUT_DIR / \u001b[33m'\u001b[39m\u001b[33msleep_mental_clean_report.md\u001b[39m\u001b[33m'\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/pathlib.py:1120\u001b[39m, in \u001b[36mPath.mkdir\u001b[39m\u001b[34m(self, mode, parents, exist_ok)\u001b[39m\n\u001b[32m   1118\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parents \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.parent == \u001b[38;5;28mself\u001b[39m:\n\u001b[32m   1119\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1120\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparents\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   1121\u001b[39m     \u001b[38;5;28mself\u001b[39m.mkdir(mode, parents=\u001b[38;5;28;01mFalse\u001b[39;00m, exist_ok=exist_ok)\n\u001b[32m   1122\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[32m   1123\u001b[39m     \u001b[38;5;66;03m# Cannot rely on checking for EEXIST, since the operating system\u001b[39;00m\n\u001b[32m   1124\u001b[39m     \u001b[38;5;66;03m# could give priority to other errors like EACCES or EROFS\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/pathlib.py:1120\u001b[39m, in \u001b[36mPath.mkdir\u001b[39m\u001b[34m(self, mode, parents, exist_ok)\u001b[39m\n\u001b[32m   1118\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parents \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.parent == \u001b[38;5;28mself\u001b[39m:\n\u001b[32m   1119\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1120\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparents\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   1121\u001b[39m     \u001b[38;5;28mself\u001b[39m.mkdir(mode, parents=\u001b[38;5;28;01mFalse\u001b[39;00m, exist_ok=exist_ok)\n\u001b[32m   1122\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[32m   1123\u001b[39m     \u001b[38;5;66;03m# Cannot rely on checking for EEXIST, since the operating system\u001b[39;00m\n\u001b[32m   1124\u001b[39m     \u001b[38;5;66;03m# could give priority to other errors like EACCES or EROFS\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/pathlib.py:1116\u001b[39m, in \u001b[36mPath.mkdir\u001b[39m\u001b[34m(self, mode, parents, exist_ok)\u001b[39m\n\u001b[32m   1112\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1113\u001b[39m \u001b[33;03mCreate a new directory at this given path.\u001b[39;00m\n\u001b[32m   1114\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1115\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1116\u001b[39m     \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1117\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n\u001b[32m   1118\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parents \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.parent == \u001b[38;5;28mself\u001b[39m:\n",
            "\u001b[31mPermissionError\u001b[39m: [Errno 13] Permission denied: '/home/camilo-pc'"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "# Rutas relativas robustas dentro del repositorio\n",
        "PROJECT_ROOT = Path.cwd()\n",
        "\n",
        "# Candidatos para localizar el CSV crudo\n",
        "raw_candidates = [\n",
        "    PROJECT_ROOT / 'NHANES2009-2012.csv',\n",
        "    PROJECT_ROOT.parent / 'NHANES2009-2012.csv',\n",
        "    PROJECT_ROOT / 'noteebook' / 'NHANES2009-2012.csv',\n",
        "]\n",
        "DATA_RAW = next((p for p in raw_candidates if p.exists()), None)\n",
        "assert DATA_RAW is not None, f'No existe archivo crudo en: {raw_candidates}'\n",
        "\n",
        "# Directorio de salida preferido\n",
        "out_candidates = [\n",
        "    PROJECT_ROOT / 'noteebook' / 'nhanes_clean',\n",
        "    PROJECT_ROOT / 'noteebook' / 'noteebook' / 'nhanes_clean',\n",
        "    PROJECT_ROOT / 'nhanes_clean',\n",
        "]\n",
        "OUT_DIR = next((p for p in out_candidates if p.parent.exists() or p.parent.parent.exists()), out_candidates[0])\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "CSV_OUT = OUT_DIR / 'NHANES2009-2012_sleep_mental_clean.csv'\n",
        "REPORT_MD = OUT_DIR / 'sleep_mental_clean_report.md'\n",
        "\n",
        "needed_original_cols = [\n",
        "    'SurveyYr', 'ID', 'Gender', 'Age', 'SleepHrsNight', 'DaysMentHlthBad'\n",
        "]\n",
        "\n",
        "# Leer encabezado para detectar columnas presentes\n",
        "header_df = pd.read_csv(DATA_RAW, nrows=0)\n",
        "available_cols = set(header_df.columns)\n",
        "present_original = [c for c in needed_original_cols if c in available_cols]\n",
        "usecols = lambda c: c in set(present_original)  # noqa: E731\n",
        "raw = pd.read_csv(DATA_RAW, usecols=usecols)\n",
        "raw.columns = [c.strip() for c in raw.columns]\n",
        "\n",
        "standard_map = {\n",
        "    'SurveyYr': 'surveyyr',\n",
        "    'ID': 'id',\n",
        "    'Gender': 'gender',\n",
        "    'Age': 'age',\n",
        "    'SleepHrsNight': 'sleephrsnight',\n",
        "    'DaysMentHlthBad': 'daysmenthlthbad',\n",
        "}\n",
        "\n",
        "df = raw.rename(columns={k: standard_map[k] for k in present_original if k in standard_map}).copy()\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tipos y coerción\n",
        "for col in ['age', 'sleephrsnight', 'daysmenthlthbad']:\n",
        "    if col in df.columns:\n",
        "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "# Duplicados por encuesta+id\n",
        "keys = [c for c in ['surveyyr', 'id'] if c in df.columns]\n",
        "rows_initial = len(df)\n",
        "if keys:\n",
        "    df = df.sort_values(keys).drop_duplicates(subset=keys, keep='first')\n",
        "rows_after_dups = len(df)\n",
        "\n",
        "# Rangos plausibles\n",
        "if 'sleephrsnight' in df.columns:\n",
        "    df.loc[(df['sleephrsnight'] < 0) | (df['sleephrsnight'] > 24), 'sleephrsnight'] = np.nan\n",
        "    df.loc[df['sleephrsnight'] == 0, 'sleephrsnight'] = np.nan\n",
        "if 'daysmenthlthbad' in df.columns:\n",
        "    df.loc[(df['daysmenthlthbad'] < 0) | (df['daysmenthlthbad'] > 30), 'daysmenthlthbad'] = np.nan\n",
        "\n",
        "# Winsorización 1-99% en sueño\n",
        "if 'sleephrsnight' in df.columns:\n",
        "    ql, qh = df['sleephrsnight'].quantile([0.01, 0.99])\n",
        "    df['sleephrsnight'] = df['sleephrsnight'].clip(lower=ql, upper=qh)\n",
        "\n",
        "# Filtro de completitud: requerir ambas variables clave\n",
        "before_complete = len(df)\n",
        "df = df[~df['sleephrsnight'].isna() & ~df['daysmenthlthbad'].isna()].copy()\n",
        "after_complete = len(df)\n",
        "\n",
        "rows_initial, rows_after_dups, before_complete, after_complete\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Normalizaciones y correlaciones\n",
        "\n",
        "def zscore(s: pd.Series) -> pd.Series:\n",
        "    m, sd = s.mean(), s.std(ddof=0)\n",
        "    return s if (pd.isna(sd) or sd == 0) else (s - m) / sd\n",
        "\n",
        "def minmax(s: pd.Series) -> pd.Series:\n",
        "    mn, mx = s.min(), s.max()\n",
        "    den = mx - mn\n",
        "    return s if (pd.isna(den) or den == 0) else (s - mn) / den\n",
        "\n",
        "if 'sleephrsnight' in df.columns:\n",
        "    df['sleephrsnight_z'] = zscore(df['sleephrsnight'])\n",
        "    df['sleephrsnight_minmax'] = minmax(df['sleephrsnight'])\n",
        "if 'daysmenthlthbad' in df.columns:\n",
        "    df['daysmenthlthbad_z'] = zscore(df['daysmenthlthbad'])\n",
        "    df['daysmenthlthbad_minmax'] = minmax(df['daysmenthlthbad'])\n",
        "\n",
        "pearson_r, pearson_p = stats.pearsonr(df['sleephrsnight'], df['daysmenthlthbad'])\n",
        "spearman_rho, spearman_p = stats.spearmanr(df['sleephrsnight'], df['daysmenthlthbad'])\n",
        "\n",
        "{\n",
        "    'pearson_r': round(float(pearson_r), 3),\n",
        "    'pearson_p': float(pearson_p),\n",
        "    'spearman_rho': round(float(spearman_rho), 3),\n",
        "    'spearman_p': float(spearman_p),\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Resumen de faltantes, valores únicos, constantes y outliers (Tukey)\n",
        "\n",
        "# Faltantes por columna\n",
        "missing_table = df.isna().sum().to_frame('missing').assign(\n",
        "    total=len(df), missing_rate=lambda d: d['missing']/d['total']\n",
        ")\n",
        "\n",
        "# Valores únicos por columna\n",
        "unique_table = df.nunique(dropna=True).to_frame('n_unique')\n",
        "\n",
        "# Columnas constantes (potencialmente redundantes en este subset)\n",
        "constant_cols = unique_table.index[unique_table['n_unique'] <= 1].tolist()\n",
        "constant_cols = [c for c in constant_cols if c not in ['id','surveyyr']]\n",
        "\n",
        "# Outliers por regla de Tukey (Q1-1.5*IQR, Q3+1.5*IQR)\n",
        "\n",
        "def tukey_outliers_count(s: pd.Series) -> int:\n",
        "    s = s.dropna()\n",
        "    if s.empty:\n",
        "        return 0\n",
        "    q1, q3 = s.quantile(0.25), s.quantile(0.75)\n",
        "    iqr = q3 - q1\n",
        "    lo, hi = q1 - 1.5*iqr, q3 + 1.5*iqr\n",
        "    return int(((s < lo) | (s > hi)).sum())\n",
        "\n",
        "outlier_counts = {}\n",
        "for col in ['sleephrsnight','daysmenthlthbad']:\n",
        "    if col in df.columns:\n",
        "        outlier_counts[col] = tukey_outliers_count(df[col])\n",
        "\n",
        "missing_table.head(), unique_table.head(), constant_cols, outlier_counts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exportar CSV limpio e informe\n",
        "export_cols = [\n",
        "    c for c in [\n",
        "        'surveyyr','id','gender','age',\n",
        "        'sleephrsnight','daysmenthlthbad',\n",
        "        'sleephrsnight_z','sleephrsnight_minmax',\n",
        "        'daysmenthlthbad_z','daysmenthlthbad_minmax'\n",
        "    ] if c in df.columns\n",
        "]\n",
        "\n",
        "df[export_cols].to_csv(CSV_OUT, index=False)\n",
        "\n",
        "report_lines = []\n",
        "report_lines.append('# Limpieza de datos: Sueño ↔ Mala Salud Mental')\n",
        "report_lines.append('')\n",
        "report_lines.append('## Variables clave')\n",
        "report_lines.append('- SleepHrsNight: horas de sueño por noche')\n",
        "report_lines.append('- DaysMentHlthBad: días de mala salud mental en los últimos 30')\n",
        "report_lines.append('')\n",
        "report_lines.append('## Resumen de filas')\n",
        "report_lines.append(f'- Filas iniciales: {rows_initial}')\n",
        "report_lines.append(f'- Eliminadas por duplicados: {rows_initial - rows_after_dups}')\n",
        "report_lines.append(f'- Eliminadas por faltantes en variables clave: {rows_after_dups - after_complete}')\n",
        "report_lines.append(f'- Filas finales para análisis: {after_complete}')\n",
        "report_lines.append('')\n",
        "report_lines.append('## Tratamientos aplicados')\n",
        "report_lines.append('- Detección y eliminación de duplicados por `surveyyr` + `id` (si disponibles).')\n",
        "report_lines.append('- Rango plausible: `sleephrsnight` en [1, 24]; `daysmenthlthbad` en [0, 30].')\n",
        "report_lines.append('- Winsorización 1%-99% en `sleephrsnight`.')\n",
        "report_lines.append('- Filtro de completitud: se requieren ambas variables clave no nulas.')\n",
        "report_lines.append('- Normalización: z-score y min-max para ambas variables.')\n",
        "report_lines.append('')\n",
        "report_lines.append('## Correlaciones')\n",
        "report_lines.append(f'- Pearson r: {pearson_r:.3f} (p={pearson_p:.3g})')\n",
        "report_lines.append(f'- Spearman ρ: {spearman_rho:.3f} (p={spearman_p:.3g})')\n",
        "report_lines.append('- Interpretación: a más horas de sueño, menos días de mala salud mental; efecto débil.')\n",
        "\n",
        "with open(REPORT_MD, 'w', encoding='utf-8') as f:\n",
        "    f.write('\\n'.join(report_lines))\n",
        "\n",
        "CSV_OUT, REPORT_MD, df[export_cols].shape\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Estrategia de limpieza y justificación\n",
        "\n",
        "- **Valores faltantes**: se exige completitud en `SleepHrsNight` y `DaysMentHlthBad` para calcular correlaciones sin sesgo de imputación; filas con faltantes en estas dos se eliminan. Otras columnas se mantienen aunque tengan NaN.\n",
        "- **Rangos plausibles**:\n",
        "  - `SleepHrsNight` en [1, 24]; 0 y fuera de rango → NaN por inviabilidad fisiológica.\n",
        "  - `DaysMentHlthBad` en [0, 30]; fuera de rango → NaN.\n",
        "- **Duplicados**: se eliminan por `surveyyr` + `id` si están presentes, conservando la primera ocurrencia.\n",
        "- **Valores atípicos (atributos)**: winsorización 1–99% en `SleepHrsNight` para reducir influencia de colas extremas sin descartar datos.\n",
        "- **Registros atípicos**: no se eliminan adicionalmente; se reporta conteo de outliers por regla de Tukey para transparencia.\n",
        "- **Atributos redundantes**: se listan columnas constantes en el subset; no se eliminan claves (`id`, `surveyyr`) aunque sean constantes.\n",
        "- **Normalización**: z-score y min-max para comparar escalas cuando sea necesario; no afecta los valores crudos exportados.\n",
        "- **Entregables**: CSV limpio con columnas clave y derivadas; informe `.md` con decisiones, conteos y correlaciones.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
